#!/bin/bash

# ==============================================
# ğŸ¯ CLS Token Fine-tuning: Command Collection
# ==============================================

echo "ğŸ¯ CLS Token Fine-tuning Commands"
echo "=================================="

# ==============================================
# ğŸš€ ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹ì–´ë“¤
# ==============================================

echo ""
echo "ğŸš€ ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹ì–´ë“¤"
echo "-------------------"

# 1. ì™„ì „í•œ ì„¤ì • (ê¶Œì¥)
echo "# 1. ì™„ì „í•œ ì„¤ì • (LoRA + Cosine + ëª¨ë“  ê¸°ëŠ¥)"
echo "python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 8 --lora_alpha 16"
echo ""

# 2. ê¸°ë³¸ ì„¤ì •
echo "# 2. ê¸°ë³¸ ì„¤ì • (Linear Classifier, LoRA ì—†ìŒ)"
echo "python main.py --name cls_basic --dataset leader_filename_47class"
echo ""

# 3. LoRAë§Œ ì‚¬ìš©
echo "# 3. LoRAë§Œ ì‚¬ìš© (Linear Classifier)"
echo "python main.py --name cls_lora_only --dataset leader_filename_47class --use_lora"
echo ""

# 4. Cosineë§Œ ì‚¬ìš©
echo "# 4. Cosineë§Œ ì‚¬ìš© (LoRA ì—†ìŒ)"
echo "python main.py --name cls_cosine_only --dataset leader_filename_47class --use_cosine"
echo ""

# ==============================================
# ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ëª…ë ¹ì–´ë“¤
# ==============================================

echo ""
echo "ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ëª…ë ¹ì–´ë“¤"
echo "------------------------------"

# í•™ìŠµë¥  ì¡°ì •
echo "# í•™ìŠµë¥  ì¡°ì •"
echo "python main.py --name cls_lora_cosine_lr1e2 --dataset leader_filename_47class --use_lora --use_cosine --learning_rate 1e-2"
echo "python main.py --name cls_lora_cosine_lr5e2 --dataset leader_filename_47class --use_lora --use_cosine --learning_rate 5e-2"
echo ""

# ë°°ì¹˜ í¬ê¸° ì¡°ì •
echo "# ë°°ì¹˜ í¬ê¸° ì¡°ì •"
echo "python main.py --name cls_lora_cosine_bs8 --dataset leader_filename_47class --use_lora --use_cosine --train_batch_size 8 --eval_batch_size 16"
echo "python main.py --name cls_lora_cosine_bs16 --dataset leader_filename_47class --use_lora --use_cosine --train_batch_size 16 --eval_batch_size 32"
echo ""

# í•™ìŠµ ìŠ¤í… ìˆ˜ ì¡°ì •
echo "# í•™ìŠµ ìŠ¤í… ìˆ˜ ì¡°ì •"
echo "python main.py --name cls_lora_cosine_10k --dataset leader_filename_47class --use_lora --use_cosine --num_steps 10000"
echo "python main.py --name cls_lora_cosine_20k --dataset leader_filename_47class --use_lora --use_cosine --num_steps 20000"
echo ""

# LoRA íŒŒë¼ë¯¸í„° ì¡°ì •
echo "# LoRA íŒŒë¼ë¯¸í„° ì¡°ì •"
echo "python main.py --name cls_lora_cosine_rank16 --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 16 --lora_alpha 32"
echo "python main.py --name cls_lora_cosine_rank32 --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 32 --lora_alpha 64"
echo ""

# ==============================================
# ğŸ–¥ï¸ GPU ì„¤ì • ëª…ë ¹ì–´ë“¤
# ==============================================

echo ""
echo "ğŸ–¥ï¸ GPU ì„¤ì • ëª…ë ¹ì–´ë“¤"
echo "-------------------"

# íŠ¹ì • GPU ì‚¬ìš©
echo "# íŠ¹ì • GPU ì‚¬ìš©"
echo "CUDA_VISIBLE_DEVICES=0 python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine"
echo "CUDA_VISIBLE_DEVICES=1 python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine"
echo ""

# CPUë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
echo "# CPUë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)"
echo "python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine --no_cuda"
echo ""

# ==============================================
# ğŸ“Š ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´ë“¤
# ==============================================

echo ""
echo "ğŸ“Š ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´ë“¤"
echo "-------------------"

# TensorBoard ë¡œê·¸ í™•ì¸
echo "# TensorBoard ë¡œê·¸ í™•ì¸"
echo "tensorboard --logdir ./runs"
echo ""

# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
echo "# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸"
echo "python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine 2>&1 | tee training.log"
echo ""

# ==============================================
# ğŸ§ª ì‹¤í—˜ ì¡°í•© ëª…ë ¹ì–´ë“¤
# ==============================================

echo ""
echo "ğŸ§ª ì‹¤í—˜ ì¡°í•© ëª…ë ¹ì–´ë“¤"
echo "-------------------"

# ì‹¤í—˜ 1: ê¸°ë³¸ vs LoRA
echo "# ì‹¤í—˜ 1: ê¸°ë³¸ vs LoRA"
echo "python main.py --name exp1_basic --dataset leader_filename_47class"
echo "python main.py --name exp1_lora --dataset leader_filename_47class --use_lora"
echo ""

# ì‹¤í—˜ 2: Linear vs Cosine
echo "# ì‹¤í—˜ 2: Linear vs Cosine"
echo "python main.py --name exp2_linear --dataset leader_filename_47class --use_lora"
echo "python main.py --name exp2_cosine --dataset leader_filename_47class --use_lora --use_cosine"
echo ""

# ì‹¤í—˜ 3: LoRA Rank ë¹„êµ
echo "# ì‹¤í—˜ 3: LoRA Rank ë¹„êµ"
echo "python main.py --name exp3_rank8 --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 8 --lora_alpha 16"
echo "python main.py --name exp3_rank16 --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 16 --lora_alpha 32"
echo "python main.py --name exp3_rank32 --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 32 --lora_alpha 64"
echo ""

# ==============================================
# ğŸš€ ë¹ ë¥¸ ì‹¤í–‰ í•¨ìˆ˜ë“¤
# ==============================================

echo ""
echo "ğŸš€ ë¹ ë¥¸ ì‹¤í–‰ í•¨ìˆ˜ë“¤"
echo "-------------------"

echo "# ê¶Œì¥ ì‹¤í–‰ (ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‹¤í–‰)"
echo "python main.py --name cls_lora_cosine --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 8 --lora_alpha 16"
echo ""

echo "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹ ë¥¸ í™•ì¸ìš©)"
echo "python main.py --name test_run --dataset leader_filename_47class --use_lora --use_cosine --num_steps 1000 --eval_every 200"
echo ""

echo "# ì™„ì „í•œ ì‹¤í—˜ (ê¸´ ì‹œê°„)"
echo "python main.py --name full_experiment --dataset leader_filename_47class --use_lora --use_cosine --lora_rank 8 --lora_alpha 16 --num_steps 10000 --eval_every 500"
echo ""

# ==============================================
# ğŸ“ ì‚¬ìš©ë²• ì•ˆë‚´
# ==============================================

echo ""
echo "ğŸ“ ì‚¬ìš©ë²• ì•ˆë‚´"
echo "-------------"
echo "1. ê¶Œì¥ ì‹¤í–‰: ìœ„ì˜ 'ê¶Œì¥ ì‹¤í–‰' ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•´ì„œ ì‹¤í–‰"
echo "2. ëª¨ë‹ˆí„°ë§: tensorboard --logdir ./runs"
echo "3. ë¡œê·¸ í™•ì¸: tail -f training.log"
echo "4. ì²´í¬í¬ì¸íŠ¸: ./output/leader_filename_47class/ í´ë”ì—ì„œ í™•ì¸"
echo ""

echo "ğŸ‰ ëª…ë ¹ì–´ ëª¨ìŒì§‘ ì™„ì„±!"
echo "ì›í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•´ì„œ ì‹¤í–‰í•˜ì„¸ìš”." 