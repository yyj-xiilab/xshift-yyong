# coding=utf-8
import torch
import torch.nn as nn
import timm

from .classifier import CosineClassifier, LinearClassifier
from .adapter import CLSAdapter, LoRALayer


class DINOSmallCLSFinetune(nn.Module):
    """DINO-Small with CLS Token Fine-tuning"""
    def __init__(self, num_classes=47, img_size=256, freeze_backbone=True, use_lora=False, use_cosine=False):
        super(DINOSmallCLSFinetune, self).__init__()
        
        print("ğŸ¯ Initializing DINO-Small with CLS Token Fine-tuning...")
        
        # DINO-Small ëª¨ë¸ ë¡œë“œ (backboneë§Œ)
        self.dino_model = timm.create_model('vit_small_patch14_dinov2', 
                                           pretrained=True, 
                                           num_classes=0,  # ë¶„ë¥˜ í—¤ë“œ ì œê±°
                                           img_size=img_size)
        
        # Backbone freeze (ì„ íƒì )
        if freeze_backbone:
            for param in self.dino_model.parameters():
                param.requires_grad = False
            print("   âœ… Backbone frozen")
        else:
            print("   ğŸ”„ Backbone trainable")
        
        # LoRA ì ìš© (ì„ íƒì )
        self.use_lora = use_lora
        if use_lora:
            self._apply_lora_to_blocks()
            print("   ğŸ”§ LoRA applied to transformer blocks")
        
        # CLS Adapter ì¶”ê°€
        self.cls_adapter = CLSAdapter(dim=384, hidden_dim=128)
        
        # Domain-specific ë¶„ë¥˜ê¸° (Cosine or Linear)
        if use_cosine:
            self.classifier = CosineClassifier(dim=384, num_classes=num_classes)
            print("   ğŸ¯ Cosine Classifier loaded")
        else:
            self.classifier = LinearClassifier(dim=384, num_classes=num_classes)
            print("   ğŸ¯ Linear Classifier loaded")
        
        # Contrastive learningì„ ìœ„í•œ projection head
        self.projection = nn.Sequential(
            nn.Linear(384, 256),
            nn.ReLU(),
            nn.Linear(256, 128)
        )
        
        print(f"   âœ… CLS Adapter + Classifier loaded: {num_classes} classes")
    
    def _apply_lora_to_blocks(self):
        """Transformer blocksì— LoRA ì ìš© (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
        # LoRAë¥¼ CLS token ì²˜ë¦¬ì—ë§Œ ì ìš©
        self.cls_lora = LoRALayer(384, 384)
        print("   ğŸ”§ LoRA applied to CLS token processing only")
        
    def get_cls_token(self, x):
        """DINOì—ì„œ CLS token ì¶”ì¶œ"""
        # DINOì˜ forward_features ëŒ€ì‹  ì§ì ‘ attention ë¸”ë¡ í†µê³¼
        x = self.dino_model.patch_embed(x)
        x = self.dino_model._pos_embed(x)
        
        # CLS token ì¶”ê°€
        cls_token = self.dino_model.cls_token.expand(x.shape[0], -1, -1)
        x = torch.cat((cls_token, x), dim=1)
        
        # Transformer blocks í†µê³¼
        for block in self.dino_model.blocks:
            x = block(x)
        
        # CLS token ì¶”ì¶œ (ì²« ë²ˆì§¸ í† í°)
        cls_token = x[:, 0]  # [B, 384]
        
        # LoRA ì ìš© (ì„ íƒì )
        if self.use_lora:
            cls_token = cls_token + self.cls_lora(cls_token)
        
        return cls_token
    
    def forward(self, x_s=None, x_t=None, ad_net=None, cp_mask=None, optimal_flag=1):
        """CLS token ì¤‘ì‹¬ forward"""
        
        if x_t is not None:  # Training mode (source + target)
            # Source domain CLS token
            cls_s = self.get_cls_token(x_s)
            cls_s_adapted = self.cls_adapter(cls_s)
            logits_s = self.classifier(cls_s_adapted)
            
            # Target domain CLS token
            cls_t = self.get_cls_token(x_t)
            cls_t_adapted = self.cls_adapter(cls_t)
            logits_t = self.classifier(cls_t_adapted)
            
            # Contrastive learningì„ ìœ„í•œ projection
            proj_s = self.projection(cls_s_adapted)
            proj_t = self.projection(cls_t_adapted)
            
            # Dummy values for compatibility
            loss_ad_local = torch.tensor(0.0).to(x_s.device)
            loss_rec = torch.tensor(0.0).to(x_s.device)
            combined_features_s = cls_s_adapted.unsqueeze(1)  # [B, 1, 384]
            combined_features_t = cls_t_adapted.unsqueeze(1)  # [B, 1, 384]
            current_cp_mask = torch.eye(325).to(x_s.device)
            
            return (logits_s, logits_t, loss_ad_local, loss_rec, 
                   combined_features_s, combined_features_t, current_cp_mask, proj_s, proj_t)
                   
        else:  # Inference mode (only source)
            cls = self.get_cls_token(x_s)
            cls_adapted = self.cls_adapter(cls)
            logits = self.classifier(cls_adapted)
            current_cp_mask = torch.eye(325).to(x_s.device)
            
            return logits, None, None, current_cp_mask
